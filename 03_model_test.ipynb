{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:09.807293500Z",
     "start_time": "2024-02-16T17:37:09.724153100Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "from timeit import default_timer as timer\n",
    "from torchmetrics.classification import MultilabelF1Score, MultilabelAccuracy\n",
    "\n",
    "# https://huggingface.co/docs/transformers/v4.17.0/en/tasks/sequence_classification\n",
    "# https://huggingface.co/docs/transformers/en/training\n",
    "# https://www.youtube.com/watch?v=TmT-sKxovb0\n",
    "# https://www.youtube.com/watch?v=f-86-HcYYi8\n",
    "# https://colab.research.google.com/github/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb#scrollTo=zHxRRzqpBf76\n",
    "# https://huggingface.co/docs/transformers/model_doc/distilbert#usage-tips"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "608458f4411e37bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_path = '04_comments_annotated-values.csv'\n",
    "data = pd.read_csv(file_path, delimiter=';')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:09.904023800Z",
     "start_time": "2024-02-16T17:37:09.810286700Z"
    }
   },
   "id": "dcbfdf82a33b855d",
   "execution_count": 231
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                  c_id                                             c_text  \\\n0  1391717608802631681  Wer so ein Profilbild wie sie hochlädt kann nu...   \n1  1389188826799673345  Willst du jetzt etwa behaupten das Querdenker ...   \n2  1385241285645291521  Aber Bild hat doch gerade deswegen und diesbez...   \n3  1385240437988986887  Das sehe ich auch genau so. Dieser Brinkhaus i...   \n4  1389640445790199809  Mit den Milliarden Unterstützungsgeldern die s...   \n\n               date  conv_id reaction1 reaction2  Generalisation  Ambiguous  \\\n0  10.05.2021 11:31      NaN       NaN       NaN             3.0        0.0   \n1  03.05.2021 12:03      NaN       NaN       NaN             3.0        1.0   \n2  22.04.2021 14:37      NaN       NaN       NaN             1.0        0.0   \n3  22.04.2021 14:33      NaN       NaN       NaN             0.0        1.0   \n4  04.05.2021 17:57      NaN       NaN       NaN             2.0        0.0   \n\n   Objective  Subjective  Disputed  Generalisation0  Generalisation1  \\\n0        0.0         1.0       0.0                0                0   \n1        0.0         1.0       0.0                0                0   \n2        1.0         1.0       0.0                0                1   \n3        0.0         1.0       0.0                1                0   \n4        0.0         1.0       0.0                0                0   \n\n   Generalisation2  Generalisation3  \n0                0                1  \n1                0                1  \n2                0                0  \n3                0                0  \n4                1                0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_id</th>\n      <th>c_text</th>\n      <th>date</th>\n      <th>conv_id</th>\n      <th>reaction1</th>\n      <th>reaction2</th>\n      <th>Generalisation</th>\n      <th>Ambiguous</th>\n      <th>Objective</th>\n      <th>Subjective</th>\n      <th>Disputed</th>\n      <th>Generalisation0</th>\n      <th>Generalisation1</th>\n      <th>Generalisation2</th>\n      <th>Generalisation3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1391717608802631681</td>\n      <td>Wer so ein Profilbild wie sie hochlädt kann nu...</td>\n      <td>10.05.2021 11:31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1389188826799673345</td>\n      <td>Willst du jetzt etwa behaupten das Querdenker ...</td>\n      <td>03.05.2021 12:03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1385241285645291521</td>\n      <td>Aber Bild hat doch gerade deswegen und diesbez...</td>\n      <td>22.04.2021 14:37</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1385240437988986887</td>\n      <td>Das sehe ich auch genau so. Dieser Brinkhaus i...</td>\n      <td>22.04.2021 14:33</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1389640445790199809</td>\n      <td>Mit den Milliarden Unterstützungsgeldern die s...</td>\n      <td>04.05.2021 17:57</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:09.909150100Z",
     "start_time": "2024-02-16T17:37:09.859225800Z"
    }
   },
   "id": "d4ead10737c28116",
   "execution_count": 232
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data.drop(labels=['c_id', 'date', 'conv_id'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:09.920156600Z",
     "start_time": "2024-02-16T17:37:09.868854900Z"
    }
   },
   "id": "64a2e61fbac700ff",
   "execution_count": 233
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              c_text reaction1 reaction2  \\\n0  Wer so ein Profilbild wie sie hochlädt kann nu...       NaN       NaN   \n1  Willst du jetzt etwa behaupten das Querdenker ...       NaN       NaN   \n2  Aber Bild hat doch gerade deswegen und diesbez...       NaN       NaN   \n3  Das sehe ich auch genau so. Dieser Brinkhaus i...       NaN       NaN   \n4  Mit den Milliarden Unterstützungsgeldern die s...       NaN       NaN   \n\n   Generalisation  Ambiguous  Objective  Subjective  Disputed  \\\n0             3.0        0.0        0.0         1.0       0.0   \n1             3.0        1.0        0.0         1.0       0.0   \n2             1.0        0.0        1.0         1.0       0.0   \n3             0.0        1.0        0.0         1.0       0.0   \n4             2.0        0.0        0.0         1.0       0.0   \n\n   Generalisation0  Generalisation1  Generalisation2  Generalisation3  \n0                0                0                0                1  \n1                0                0                0                1  \n2                0                1                0                0  \n3                1                0                0                0  \n4                0                0                1                0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_text</th>\n      <th>reaction1</th>\n      <th>reaction2</th>\n      <th>Generalisation</th>\n      <th>Ambiguous</th>\n      <th>Objective</th>\n      <th>Subjective</th>\n      <th>Disputed</th>\n      <th>Generalisation0</th>\n      <th>Generalisation1</th>\n      <th>Generalisation2</th>\n      <th>Generalisation3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wer so ein Profilbild wie sie hochlädt kann nu...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Willst du jetzt etwa behaupten das Querdenker ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aber Bild hat doch gerade deswegen und diesbez...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Das sehe ich auch genau so. Dieser Brinkhaus i...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mit den Milliarden Unterstützungsgeldern die s...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:09.964260100Z",
     "start_time": "2024-02-16T17:37:09.894024400Z"
    }
   },
   "id": "521a979d09eab60f",
   "execution_count": 234
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ba42cb29e4cdfbe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target_list = ['Generalisation0', 'Generalisation1', 'Generalisation2', 'Generalisation3', 'Ambiguous', 'Objective', 'Subjective', 'Disputed']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:10.084846900Z",
     "start_time": "2024-02-16T17:37:09.945157500Z"
    }
   },
   "id": "1422dbc9d69f6b84",
   "execution_count": 235
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:10.224377700Z",
     "start_time": "2024-02-16T17:37:10.039780600Z"
    }
   },
   "id": "387a20c9131d19a6",
   "execution_count": 236
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "def get_encodings(text, reaction1, reaction2):\n",
    "    text = str(text)\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    reaction1 = str(reaction1)\n",
    "    reaction1 = \" \".join(reaction1.split())\n",
    "    \n",
    "    reaction2 = str(reaction2)\n",
    "    reaction2 = \" \".join(reaction2.split())\n",
    "    \n",
    "    encodings = tokenizer.encode_plus(\n",
    "            text + ' [SEP] ' + reaction1 + ' ' + reaction2, \n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    \n",
    "    return encodings['input_ids'], encodings['attention_mask'], encodings['token_type_ids']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:10.811927Z",
     "start_time": "2024-02-16T17:37:10.228376100Z"
    }
   },
   "id": "c75a413702e0692a",
   "execution_count": 237
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset (torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.title = self.df['c_text']\n",
    "        self.reaction1 = self.df['reaction1']\n",
    "        self.reaction2 = self.df['reaction2']\n",
    "        self.targets = self.df[target_list].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids, attention_mask, token_type_ids = get_encodings(self.title[index], self.reaction1[index], self.reaction2[index])\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids.flatten(),\n",
    "            'attention_mask': attention_mask.flatten(),\n",
    "            'token_type_ids': token_type_ids.flatten(),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:10.823986500Z",
     "start_time": "2024-02-16T17:37:10.812926800Z"
    }
   },
   "id": "19838c24cd78475a",
   "execution_count": 238
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0cce338ae2f8979"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 12)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "data = data[0:200]\n",
    "print(data.shape)\n",
    "train_data = data.sample(frac=train_size, random_state=200).reset_index(drop=True)\n",
    "validation_data = data.drop(train_data.index).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:10.829837500Z",
     "start_time": "2024-02-16T17:37:10.823986500Z"
    }
   },
   "id": "f6dc9c521b03eb81",
   "execution_count": 239
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = CustomDataset(train_data, tokenizer, MAX_LEN)\n",
    "validation_data = CustomDataset(validation_data, tokenizer, MAX_LEN)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:10.894918800Z",
     "start_time": "2024-02-16T17:37:10.832896200Z"
    }
   },
   "id": "c98ceceb0f1dec9c",
   "execution_count": 240
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "validation_data_loader = torch.utils.data.DataLoader(validation_data, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:10.896918900Z",
     "start_time": "2024-02-16T17:37:10.841826700Z"
    }
   },
   "id": "47978d8dfe1ea61e",
   "execution_count": 241
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d13e73dda01415c4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:10.896918900Z",
     "start_time": "2024-02-16T17:37:10.849734600Z"
    }
   },
   "id": "ef570748a9fcbd15",
   "execution_count": 242
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath, model, optimizer):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:10.897918500Z",
     "start_time": "2024-02-16T17:37:10.857294400Z"
    }
   },
   "id": "baf1ebf16817107c",
   "execution_count": 243
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, file_path, best_model_path):\n",
    "    torch.save(state, file_path)\n",
    "    if is_best:\n",
    "        shutil.copy(file_path, best_model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:10.898920Z",
     "start_time": "2024-02-16T17:37:10.864499700Z"
    }
   },
   "id": "cbf72a1ad72fb292",
   "execution_count": 244
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(768, 8)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        pooler = self.classifier(pooler)\n",
    "        output = self.sigmoid(pooler)\n",
    "        \n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:10.899876800Z",
     "start_time": "2024-02-16T17:37:10.878378400Z"
    }
   },
   "id": "7fccbde71b8662c5",
   "execution_count": 245
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "BERTClass(\n  (l1): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=8, bias=True)\n  (sigmoid): Sigmoid()\n)"
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClass()\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:12.469336600Z",
     "start_time": "2024-02-16T17:37:10.886901200Z"
    }
   },
   "id": "ee90deb2bcb98ceb",
   "execution_count": 246
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_function(output, target):\n",
    "    return torch.nn.BCEWithLogitsLoss()(output, target)\n",
    "\n",
    "def accuracy_function(output, target):\n",
    "    mlaNone = MultilabelAccuracy(num_labels=8, average='none', threshold=0.5)\n",
    "    mlaMiro = MultilabelAccuracy(num_labels=8, average='micro', threshold=0.5)\n",
    "    mlaMacro = MultilabelAccuracy(num_labels=8, average='macro', threshold=0.5)\n",
    "    mlaWeighted = MultilabelAccuracy(num_labels=8, average='weighted', threshold=0.5)\n",
    "    return f'Accuracy: \\tNone: {mlaNone(output, target)} \\tMicro: {mlaMiro(output, target)} \\tMacro: {mlaMacro(output, target)} \\tWeighted: {mlaWeighted(output, target)}'\n",
    "\n",
    "def f1_score_function(output, target):\n",
    "    mlf1None = MultilabelF1Score(num_labels=8, average='none', threshold=0.5)\n",
    "    mlf1Miro = MultilabelF1Score(num_labels=8, average='micro', threshold=0.5)\n",
    "    mlf1Macro = MultilabelF1Score(num_labels=8, average='macro', threshold=0.5)\n",
    "    mlf1Weighted = MultilabelF1Score(num_labels=8, average='weighted', threshold=0.5)\n",
    "    return f'F1 Score: \\tNone: {mlf1None(output, target)} \\tMicro: {mlf1Miro(output, target)} \\tMacro: {mlf1Macro(output, target)} \\tWeighted: {mlf1Weighted(output, target)}'\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:12.486817300Z",
     "start_time": "2024-02-16T17:37:12.462292800Z"
    }
   },
   "id": "5c65abe9e8d153af",
   "execution_count": 247
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(n_epochs, training_loader, validation_loader, model, optimizer, checkpoint_path, best_model_path):\n",
    "    valid_loss_min = np.Inf\n",
    "    model_start_time = timer()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        epoch_start_time = timer()\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        # Training Loop\n",
    "        model.train()\n",
    "        \n",
    "        train_output = []\n",
    "        train_target = []\n",
    "        \n",
    "        for index, batch in enumerate(training_loader, 0):\n",
    "            input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "            attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = batch['targets'].to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_function(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += (1/(index+1))*(loss.item()-train_loss)\n",
    "            \n",
    "            train_output.append(outputs)\n",
    "            train_target.append(targets)\n",
    "            \n",
    "        train_accuracy = accuracy_function(torch.cat(train_output), torch.cat(train_target))\n",
    "        train_f1_score = f1_score_function(torch.cat(train_output), torch.cat(train_target))\n",
    "            \n",
    "        # Validation Loop\n",
    "        model.eval()\n",
    "        \n",
    "        validation_output = []\n",
    "        validation_target = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for index, batch in enumerate(validation_loader, 0):\n",
    "                input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "                attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "                token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "                targets = batch['targets'].to(device, dtype=torch.float)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "                \n",
    "                loss = loss_function(outputs, targets)\n",
    "                valid_loss += (1/(index+1))*(loss.item()-valid_loss)\n",
    "                \n",
    "                validation_output.append(outputs)\n",
    "                validation_target.append(targets)\n",
    "                \n",
    "        valid_accuracy = accuracy_function(torch.cat(validation_output), torch.cat(validation_target))\n",
    "        valid_f1_score = f1_score_function(torch.cat(validation_output), torch.cat(validation_target))\n",
    "                \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'valid_loss_min': valid_loss,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        \n",
    "        if valid_loss < valid_loss_min:\n",
    "            valid_loss_min = valid_loss\n",
    "            save_checkpoint(checkpoint, True, checkpoint_path, best_model_path)\n",
    "        else:\n",
    "            save_checkpoint(checkpoint, False, checkpoint_path, best_model_path)\n",
    "        \n",
    "        print(f'\\n\\nEpoch: {epoch} \\tTime: {int(timer()-epoch_start_time)}s \\tTraining Loss: {train_loss} \\tValidation Loss: {valid_loss}')\n",
    "        print(f'\\tTraining: \\n\\t\\t{train_accuracy} \\n\\t\\t{train_f1_score}')\n",
    "        print(f'\\tValidation: \\n\\t\\t{valid_accuracy} \\n\\t\\t{valid_f1_score}')\n",
    "        \n",
    "    print(f'\\n\\nTraining time: {int(timer()-model_start_time)}s')\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:37:12.534905500Z",
     "start_time": "2024-02-16T17:37:12.477817700Z"
    }
   },
   "id": "40390e5e2ca36958",
   "execution_count": 248
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and evaluate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6661621cfb8ea3f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 1 \tTime: 276s \tTraining Loss: 0.8081438899040222 \tValidation Loss: 0.796354204416275\n",
      "\tTraining: \n",
      "\t\tAccuracy: \tNone: tensor([0.6750, 0.4563, 0.5500, 0.8250, 0.5312, 0.3688, 0.9187, 0.8813]) \tMicro: 0.6507812738418579 \tMacro: 0.6507812738418579 \tWeighted: 0.6744427680969238 \n",
      "\t\tF1 Score: \tNone: tensor([0.0714, 0.3256, 0.5000, 0.0667, 0.3590, 0.3567, 0.9577, 0.0000]) \tMicro: 0.5338894724845886 \tMacro: 0.329624205827713 \tWeighted: 0.5487957000732422\n",
      "\tValidation: \n",
      "\t\tAccuracy: \tNone: tensor([0.5750, 0.6500, 0.7250, 0.9750, 0.5250, 0.7250, 0.9500, 1.0000]) \tMicro: 0.765625 \tMacro: 0.7656249403953552 \tWeighted: 0.738084077835083 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9744, 0.0000]) \tMicro: 0.503311276435852 \tMacro: 0.12179487198591232 \tWeighted: 0.34603404998779297\n",
      "\n",
      "\n",
      "Epoch: 2 \tTime: 288s \tTraining Loss: 0.7997676372528076 \tValidation Loss: 0.7854457497596741\n",
      "\tTraining: \n",
      "\t\tAccuracy: \tNone: tensor([0.7063, 0.6812, 0.6687, 0.9375, 0.5312, 0.7375, 0.9375, 1.0000]) \tMicro: 0.7749999761581421 \tMacro: 0.7750000357627869 \tWeighted: 0.7599246501922607 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.2154, 0.1587, 0.0000, 0.0964, 0.1250, 0.9677, 0.0000]) \tMicro: 0.5399361252784729 \tMacro: 0.1954052746295929 \tWeighted: 0.42272505164146423\n",
      "\tValidation: \n",
      "\t\tAccuracy: \tNone: tensor([0.5750, 0.6500, 0.8000, 0.9750, 0.5250, 0.7500, 0.9500, 1.0000]) \tMicro: 0.778124988079071 \tMacro: 0.778124988079071 \tWeighted: 0.746027946472168 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9744, 0.0000]) \tMicro: 0.5170068144798279 \tMacro: 0.12179487198591232 \tWeighted: 0.34603404998779297\n",
      "\n",
      "\n",
      "Epoch: 3 \tTime: 277s \tTraining Loss: 0.7885587215423584 \tValidation Loss: 0.7735808491706848\n",
      "\tTraining: \n",
      "\t\tAccuracy: \tNone: tensor([0.7063, 0.6812, 0.6812, 0.9375, 0.5500, 0.7875, 0.9375, 1.0000]) \tMicro: 0.78515625 \tMacro: 0.78515625 \tWeighted: 0.7688102722167969 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9677, 0.0000]) \tMicro: 0.52173912525177 \tMacro: 0.12096773833036423 \tWeighted: 0.3497862219810486\n",
      "\tValidation: \n",
      "\t\tAccuracy: \tNone: tensor([0.5750, 0.6500, 0.8000, 0.9750, 0.5250, 0.7500, 0.9500, 1.0000]) \tMicro: 0.778124988079071 \tMacro: 0.778124988079071 \tWeighted: 0.746027946472168 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9744, 0.0000]) \tMicro: 0.5170068144798279 \tMacro: 0.12179487198591232 \tWeighted: 0.34603404998779297\n",
      "\n",
      "\n",
      "Training time: 842s\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = './model/checkpoint.pth'\n",
    "BEST_MODEL_PATH = './model/best_model.pth'\n",
    "trained_model = train_model(EPOCHS, train_data_loader, validation_data_loader, model, optimizer, CHECKPOINT_PATH, BEST_MODEL_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:51:15.202475500Z",
     "start_time": "2024-02-16T17:37:12.503910Z"
    }
   },
   "id": "da94e78a115d5864",
   "execution_count": 249
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89299a35ae1a6846"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_model = BERTClass()\n",
    "pred_model.to(device)\n",
    "model = load_checkpoint(BEST_MODEL_PATH, pred_model, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:51:19.372901300Z",
     "start_time": "2024-02-16T17:51:15.193460700Z"
    }
   },
   "id": "f18f8acb1f1606ec",
   "execution_count": 250
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:51:19.800021200Z",
     "start_time": "2024-02-16T17:51:19.374901300Z"
    }
   },
   "id": "f70a1da4d04203e1",
   "execution_count": 251
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get Predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63794d5155241a97"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_prediction(text): \n",
    "    input_ids, attention_mask, token_type_ids = get_encodings(text, '', '')\n",
    "    \n",
    "    pred_model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = input_ids.to(device, dtype=torch.long)\n",
    "        attention_mask = attention_mask.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        \n",
    "        outputs = pred_model(input_ids, attention_mask, token_type_ids)\n",
    "        \n",
    "        print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:51:19.813473500Z",
     "start_time": "2024-02-16T17:51:19.802018Z"
    }
   },
   "id": "d0cfa2385a37cc09",
   "execution_count": 252
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4407, 0.4253, 0.4599, 0.4223, 0.4672, 0.4386, 0.5555, 0.4122]])\n",
      "tensor([[0.4390, 0.4483, 0.4492, 0.4221, 0.4617, 0.4304, 0.5604, 0.4117]])\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"Seit 1960 steigt jedes Jahr die Zahl der Eisbären, Ozonloch über Arktis weg. Tote von Naturkatastrophen so wenig wie nie. Nie soviel Wald wie jetzt. Der Welt geht's saugut. Nur einzelne schieben Panik und die Medien steigen ein, verkauft sich eben gut.\")\n",
    "get_prediction(\"Der Impf-Apartheider? Hattest du Whisky zum Frühstück?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:51:21.539090800Z",
     "start_time": "2024-02-16T17:51:19.808473500Z"
    }
   },
   "id": "d1540c8f500c02a",
   "execution_count": 253
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
