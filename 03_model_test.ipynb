{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:15.205180700Z",
     "start_time": "2024-02-16T16:24:15.054417Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "from timeit import default_timer as timer\n",
    "from torchmetrics.classification import MultilabelF1Score, MultilabelAccuracy\n",
    "\n",
    "# https://huggingface.co/docs/transformers/v4.17.0/en/tasks/sequence_classification\n",
    "# https://huggingface.co/docs/transformers/en/training\n",
    "# https://www.youtube.com/watch?v=TmT-sKxovb0\n",
    "# https://www.youtube.com/watch?v=f-86-HcYYi8\n",
    "# https://colab.research.google.com/github/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb#scrollTo=zHxRRzqpBf76\n",
    "# https://huggingface.co/docs/transformers/model_doc/distilbert#usage-tips"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "608458f4411e37bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_path = '04_comments_annotated-values.csv'\n",
    "data = pd.read_csv(file_path, delimiter=';')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:15.270185900Z",
     "start_time": "2024-02-16T16:24:15.207180700Z"
    }
   },
   "id": "dcbfdf82a33b855d",
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                  c_id                                             c_text  \\\n0  1391717608802631681  Wer so ein Profilbild wie sie hochlädt kann nu...   \n1  1389188826799673345  Willst du jetzt etwa behaupten das Querdenker ...   \n2  1385241285645291521  Aber Bild hat doch gerade deswegen und diesbez...   \n3  1385240437988986887  Das sehe ich auch genau so. Dieser Brinkhaus i...   \n4  1389640445790199809  Mit den Milliarden Unterstützungsgeldern die s...   \n\n               date  conv_id reaction1 reaction2  Generalisation  Ambiguous  \\\n0  10.05.2021 11:31      NaN       NaN       NaN             3.0        0.0   \n1  03.05.2021 12:03      NaN       NaN       NaN             3.0        1.0   \n2  22.04.2021 14:37      NaN       NaN       NaN             1.0        0.0   \n3  22.04.2021 14:33      NaN       NaN       NaN             0.0        1.0   \n4  04.05.2021 17:57      NaN       NaN       NaN             2.0        0.0   \n\n   Objective  Subjective  Disputed  Generalisation0  Generalisation1  \\\n0        0.0         1.0       0.0                0                0   \n1        0.0         1.0       0.0                0                0   \n2        1.0         1.0       0.0                0                1   \n3        0.0         1.0       0.0                1                0   \n4        0.0         1.0       0.0                0                0   \n\n   Generalisation2  Generalisation3  \n0                0                1  \n1                0                1  \n2                0                0  \n3                0                0  \n4                1                0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_id</th>\n      <th>c_text</th>\n      <th>date</th>\n      <th>conv_id</th>\n      <th>reaction1</th>\n      <th>reaction2</th>\n      <th>Generalisation</th>\n      <th>Ambiguous</th>\n      <th>Objective</th>\n      <th>Subjective</th>\n      <th>Disputed</th>\n      <th>Generalisation0</th>\n      <th>Generalisation1</th>\n      <th>Generalisation2</th>\n      <th>Generalisation3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1391717608802631681</td>\n      <td>Wer so ein Profilbild wie sie hochlädt kann nu...</td>\n      <td>10.05.2021 11:31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1389188826799673345</td>\n      <td>Willst du jetzt etwa behaupten das Querdenker ...</td>\n      <td>03.05.2021 12:03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1385241285645291521</td>\n      <td>Aber Bild hat doch gerade deswegen und diesbez...</td>\n      <td>22.04.2021 14:37</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1385240437988986887</td>\n      <td>Das sehe ich auch genau so. Dieser Brinkhaus i...</td>\n      <td>22.04.2021 14:33</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1389640445790199809</td>\n      <td>Mit den Milliarden Unterstützungsgeldern die s...</td>\n      <td>04.05.2021 17:57</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:15.275183300Z",
     "start_time": "2024-02-16T16:24:15.245767900Z"
    }
   },
   "id": "d4ead10737c28116",
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: Correctly handle reactions\n",
    "data.drop(labels=['c_id', 'date', 'conv_id', 'reaction1', 'reaction2'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:15.324023500Z",
     "start_time": "2024-02-16T16:24:15.277182500Z"
    }
   },
   "id": "64a2e61fbac700ff",
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              c_text  Generalisation  \\\n0  Wer so ein Profilbild wie sie hochlädt kann nu...             3.0   \n1  Willst du jetzt etwa behaupten das Querdenker ...             3.0   \n2  Aber Bild hat doch gerade deswegen und diesbez...             1.0   \n3  Das sehe ich auch genau so. Dieser Brinkhaus i...             0.0   \n4  Mit den Milliarden Unterstützungsgeldern die s...             2.0   \n\n   Ambiguous  Objective  Subjective  Disputed  Generalisation0  \\\n0        0.0        0.0         1.0       0.0                0   \n1        1.0        0.0         1.0       0.0                0   \n2        0.0        1.0         1.0       0.0                0   \n3        1.0        0.0         1.0       0.0                1   \n4        0.0        0.0         1.0       0.0                0   \n\n   Generalisation1  Generalisation2  Generalisation3  \n0                0                0                1  \n1                0                0                1  \n2                1                0                0  \n3                0                0                0  \n4                0                1                0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_text</th>\n      <th>Generalisation</th>\n      <th>Ambiguous</th>\n      <th>Objective</th>\n      <th>Subjective</th>\n      <th>Disputed</th>\n      <th>Generalisation0</th>\n      <th>Generalisation1</th>\n      <th>Generalisation2</th>\n      <th>Generalisation3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wer so ein Profilbild wie sie hochlädt kann nu...</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Willst du jetzt etwa behaupten das Querdenker ...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aber Bild hat doch gerade deswegen und diesbez...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Das sehe ich auch genau so. Dieser Brinkhaus i...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mit den Milliarden Unterstützungsgeldern die s...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:15.389548Z",
     "start_time": "2024-02-16T16:24:15.310316300Z"
    }
   },
   "id": "521a979d09eab60f",
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ba42cb29e4cdfbe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target_list = ['Generalisation0', 'Generalisation1', 'Generalisation2', 'Generalisation3', 'Ambiguous', 'Objective', 'Subjective', 'Disputed']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:15.456928600Z",
     "start_time": "2024-02-16T16:24:15.391543900Z"
    }
   },
   "id": "1422dbc9d69f6b84",
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MAX_LEN = 300\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:15.520934800Z",
     "start_time": "2024-02-16T16:24:15.452160700Z"
    }
   },
   "id": "387a20c9131d19a6",
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "def get_encodings(text):\n",
    "    text = str(text)\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    encodings = tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    \n",
    "    return encodings['input_ids'], encodings['attention_mask'], encodings['token_type_ids']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:15.982630400Z",
     "start_time": "2024-02-16T16:24:15.508930500Z"
    }
   },
   "id": "c75a413702e0692a",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset (torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.title = self.df['c_text']\n",
    "        self.targets = self.df[target_list].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids, attention_mask, token_type_ids = get_encodings(self.title[index])\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids.flatten(),\n",
    "            'attention_mask': attention_mask.flatten(),\n",
    "            'token_type_ids': token_type_ids.flatten(),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:15.993628Z",
     "start_time": "2024-02-16T16:24:15.986629300Z"
    }
   },
   "id": "19838c24cd78475a",
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0cce338ae2f8979"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 10)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "data = data[0:200]\n",
    "print(data.shape)\n",
    "train_data = data.sample(frac=train_size, random_state=200).reset_index(drop=True)\n",
    "validation_data = data.drop(train_data.index).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:16.045717900Z",
     "start_time": "2024-02-16T16:24:15.993628Z"
    }
   },
   "id": "f6dc9c521b03eb81",
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = CustomDataset(train_data, tokenizer, MAX_LEN)\n",
    "validation_data = CustomDataset(validation_data, tokenizer, MAX_LEN)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:16.050439500Z",
     "start_time": "2024-02-16T16:24:16.007237Z"
    }
   },
   "id": "c98ceceb0f1dec9c",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "validation_data_loader = torch.utils.data.DataLoader(validation_data, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:16.068097900Z",
     "start_time": "2024-02-16T16:24:16.015560Z"
    }
   },
   "id": "47978d8dfe1ea61e",
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d13e73dda01415c4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:16.108098600Z",
     "start_time": "2024-02-16T16:24:16.036432400Z"
    }
   },
   "id": "ef570748a9fcbd15",
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath, model, optimizer):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:16.110140100Z",
     "start_time": "2024-02-16T16:24:16.045717900Z"
    }
   },
   "id": "baf1ebf16817107c",
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, file_path, best_model_path):\n",
    "    torch.save(state, file_path)\n",
    "    if is_best:\n",
    "        shutil.copy(file_path, best_model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:16.112123600Z",
     "start_time": "2024-02-16T16:24:16.053437400Z"
    }
   },
   "id": "cbf72a1ad72fb292",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(768, 8)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        pooler = self.classifier(pooler)\n",
    "        output = self.sigmoid(pooler)\n",
    "        \n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:16.113123800Z",
     "start_time": "2024-02-16T16:24:16.061762700Z"
    }
   },
   "id": "7fccbde71b8662c5",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "BERTClass(\n  (l1): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=8, bias=True)\n  (sigmoid): Sigmoid()\n)"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClass()\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:17.288368100Z",
     "start_time": "2024-02-16T16:24:16.070100300Z"
    }
   },
   "id": "ee90deb2bcb98ceb",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_function(output, target):\n",
    "    return torch.nn.BCEWithLogitsLoss()(output, target)\n",
    "\n",
    "def accuracy_function(output, target):\n",
    "    mlaNone = MultilabelAccuracy(num_labels=8, average='none', threshold=0.5)\n",
    "    mlaMiro = MultilabelAccuracy(num_labels=8, average='micro', threshold=0.5)\n",
    "    mlaMacro = MultilabelAccuracy(num_labels=8, average='macro', threshold=0.5)\n",
    "    mlaWeighted = MultilabelAccuracy(num_labels=8, average='weighted', threshold=0.5)\n",
    "    return f'Accuracy: \\tNone: {mlaNone(output, target)} \\tMicro: {mlaMiro(output, target)} \\tMacro: {mlaMacro(output, target)} \\tWeighted: {mlaWeighted(output, target)}'\n",
    "\n",
    "def f1_score_function(output, target):\n",
    "    mlf1None = MultilabelF1Score(num_labels=8, average='none', threshold=0.5)\n",
    "    mlf1Miro = MultilabelF1Score(num_labels=8, average='micro', threshold=0.5)\n",
    "    mlf1Macro = MultilabelF1Score(num_labels=8, average='macro', threshold=0.5)\n",
    "    mlf1Weighted = MultilabelF1Score(num_labels=8, average='weighted', threshold=0.5)\n",
    "    return f'F1 Score: \\tNone: {mlf1None(output, target)} \\tMicro: {mlf1Miro(output, target)} \\tMacro: {mlf1Macro(output, target)} \\tWeighted: {mlf1Weighted(output, target)}'\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:17.442936600Z",
     "start_time": "2024-02-16T16:24:17.290365200Z"
    }
   },
   "id": "5c65abe9e8d153af",
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(n_epochs, training_loader, validation_loader, model, optimizer, checkpoint_path, best_model_path):\n",
    "    valid_loss_min = np.Inf\n",
    "    model_start_time = timer()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        epoch_start_time = timer()\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        # Training Loop\n",
    "        model.train()\n",
    "        \n",
    "        train_output = []\n",
    "        train_target = []\n",
    "        \n",
    "        for index, batch in enumerate(training_loader, 0):\n",
    "            input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "            attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = batch['targets'].to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_function(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += (1/(index+1))*(loss.item()-train_loss)\n",
    "            \n",
    "            train_output.append(outputs)\n",
    "            train_target.append(targets)\n",
    "            \n",
    "        train_accuracy = accuracy_function(torch.cat(train_output), torch.cat(train_target))\n",
    "        train_f1_score = f1_score_function(torch.cat(train_output), torch.cat(train_target))\n",
    "            \n",
    "        # Validation Loop\n",
    "        model.eval()\n",
    "        \n",
    "        validation_output = []\n",
    "        validation_target = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for index, batch in enumerate(validation_loader, 0):\n",
    "                input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "                attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "                token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "                targets = batch['targets'].to(device, dtype=torch.float)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "                \n",
    "                loss = loss_function(outputs, targets)\n",
    "                valid_loss += (1/(index+1))*(loss.item()-valid_loss)\n",
    "                \n",
    "                validation_output.append(outputs)\n",
    "                validation_target.append(targets)\n",
    "                \n",
    "        valid_accuracy = accuracy_function(torch.cat(validation_output), torch.cat(validation_target))\n",
    "        valid_f1_score = f1_score_function(torch.cat(validation_output), torch.cat(validation_target))\n",
    "                \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'valid_loss_min': valid_loss,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        \n",
    "        if valid_loss < valid_loss_min:\n",
    "            valid_loss_min = valid_loss\n",
    "            save_checkpoint(checkpoint, True, checkpoint_path, best_model_path)\n",
    "        else:\n",
    "            save_checkpoint(checkpoint, False, checkpoint_path, best_model_path)\n",
    "        \n",
    "        print(f'\\n\\nEpoch: {epoch} \\tTime: {int(timer()-epoch_start_time)}s \\tTraining Loss: {train_loss} \\tValidation Loss: {valid_loss}')\n",
    "        print(f'\\tTraining: \\n\\t\\t{train_accuracy} \\n\\t\\t{train_f1_score}')\n",
    "        print(f'\\tValidation: \\n\\t\\t{valid_accuracy} \\n\\t\\t{valid_f1_score}')\n",
    "        \n",
    "    print(f'\\n\\nTraining time: {timer()-model_start_time}')\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:24:17.462451600Z",
     "start_time": "2024-02-16T16:24:17.348367100Z"
    }
   },
   "id": "40390e5e2ca36958",
   "execution_count": 124
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and evaluate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6661621cfb8ea3f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 1 \tTime: 141s \tTraining Loss: 0.8053711891174317 \tValidation Loss: 0.7937235832214355\n",
      "\tTraining: \n",
      "\t\tAccuracy: \tNone: tensor([0.7063, 0.3750, 0.6625, 0.5500, 0.5063, 0.6750, 0.8562, 0.9750]) \tMicro: 0.663281261920929 \tMacro: 0.663281261920929 \tWeighted: 0.6733584403991699 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.3976, 0.0000, 0.1000, 0.4148, 0.2121, 0.9226, 0.0000]) \tMicro: 0.492343932390213 \tMacro: 0.25588566064834595 \tWeighted: 0.4740716516971588\n",
      "\tValidation: \n",
      "\t\tAccuracy: \tNone: tensor([0.5750, 0.4750, 0.8000, 0.9750, 0.5250, 0.7500, 0.9500, 1.0000]) \tMicro: 0.7562500238418579 \tMacro: 0.7562499642372131 \tWeighted: 0.7231308221817017 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.0870, 0.0000, 0.0000, 0.4865, 0.0000, 0.9744, 0.0000]) \tMicro: 0.5517241358757019 \tMacro: 0.19347524642944336 \tWeighted: 0.4437969923019409\n",
      "\n",
      "\n",
      "Epoch: 2 \tTime: 140s \tTraining Loss: 0.7967085838317871 \tValidation Loss: 0.783710777759552\n",
      "\tTraining: \n",
      "\t\tAccuracy: \tNone: tensor([0.7063, 0.5938, 0.6812, 0.9125, 0.5312, 0.7875, 0.9438, 1.0000]) \tMicro: 0.76953125 \tMacro: 0.76953125 \tWeighted: 0.7564608454704285 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.1096, 0.0000, 0.1250, 0.5342, 0.1053, 0.9709, 0.0000]) \tMicro: 0.5755395889282227 \tMacro: 0.2306109368801117 \tWeighted: 0.46869564056396484\n",
      "\tValidation: \n",
      "\t\tAccuracy: \tNone: tensor([0.5750, 0.6500, 0.8000, 0.9750, 0.5000, 0.7500, 0.9500, 1.0000]) \tMicro: 0.7749999761581421 \tMacro: 0.7749999761581421 \tWeighted: 0.7415887117385864 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6429, 0.0000, 0.9744, 0.0000]) \tMicro: 0.6086956262588501 \tMacro: 0.20215201377868652 \tWeighted: 0.460186243057251\n",
      "\n",
      "\n",
      "Epoch: 3 \tTime: 140s \tTraining Loss: 0.7859192013740539 \tValidation Loss: 0.7713186740875244\n",
      "\tTraining: \n",
      "\t\tAccuracy: \tNone: tensor([0.7063, 0.6750, 0.6812, 0.9375, 0.5312, 0.7875, 0.9375, 1.0000]) \tMicro: 0.782031238079071 \tMacro: 0.782031238079071 \tWeighted: 0.7647892236709595 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6479, 0.0000, 0.9677, 0.0000]) \tMicro: 0.6108786463737488 \tMacro: 0.20195364952087402 \tWeighted: 0.46219077706336975\n",
      "\tValidation: \n",
      "\t\tAccuracy: \tNone: tensor([0.5750, 0.6500, 0.8000, 0.9750, 0.4750, 0.7500, 0.9500, 1.0000]) \tMicro: 0.7718750238418579 \tMacro: 0.7718749642372131 \tWeighted: 0.7371494770050049 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6441, 0.0000, 0.9744, 0.0000]) \tMicro: 0.6096256971359253 \tMacro: 0.20230334997177124 \tWeighted: 0.4604012370109558\n",
      "\n",
      "\n",
      "Training time: 422.59725360001903\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = './model/checkpoint.pth'\n",
    "BEST_MODEL_PATH = './model/best_model.pth'\n",
    "trained_model = train_model(EPOCHS, train_data_loader, validation_data_loader, model, optimizer, CHECKPOINT_PATH, BEST_MODEL_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:31:19.972776600Z",
     "start_time": "2024-02-16T16:24:17.369932500Z"
    }
   },
   "id": "da94e78a115d5864",
   "execution_count": 125
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89299a35ae1a6846"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_model = BERTClass()\n",
    "pred_model.to(device)\n",
    "model = load_checkpoint(BEST_MODEL_PATH, pred_model, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:31:21.723896200Z",
     "start_time": "2024-02-16T16:31:19.974805700Z"
    }
   },
   "id": "f18f8acb1f1606ec",
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:31:22.368351700Z",
     "start_time": "2024-02-16T16:31:21.725897100Z"
    }
   },
   "id": "f70a1da4d04203e1",
   "execution_count": 127
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get Predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63794d5155241a97"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_prediction(text): \n",
    "    input_ids, attention_mask, token_type_ids = get_encodings(text)\n",
    "    \n",
    "    pred_model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = input_ids.to(device, dtype=torch.long)\n",
    "        attention_mask = attention_mask.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        \n",
    "        outputs = pred_model(input_ids, attention_mask, token_type_ids)\n",
    "        \n",
    "        print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:31:22.379483500Z",
     "start_time": "2024-02-16T16:31:22.372351400Z"
    }
   },
   "id": "d0cfa2385a37cc09",
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3811, 0.4421, 0.4189, 0.4129, 0.5201, 0.4009, 0.5635, 0.3939]])\n",
      "tensor([[0.3992, 0.4554, 0.4243, 0.4069, 0.5386, 0.3892, 0.5836, 0.4050]])\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"Seit 1960 steigt jedes Jahr die Zahl der Eisbären, Ozonloch über Arktis weg. Tote von Naturkatastrophen so wenig wie nie. Nie soviel Wald wie jetzt. Der Welt geht's saugut. Nur einzelne schieben Panik und die Medien steigen ein, verkauft sich eben gut.\")\n",
    "get_prediction(\"Der Impf-Apartheider? Hattest du Whisky zum Frühstück?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:31:23.272428600Z",
     "start_time": "2024-02-16T16:31:22.379483500Z"
    }
   },
   "id": "d1540c8f500c02a",
   "execution_count": 129
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
