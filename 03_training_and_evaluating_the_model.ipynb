{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:31.457313800Z",
     "start_time": "2024-04-19T14:24:31.056154100Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n",
    "from timeit import default_timer as timer\n",
    "from torchmetrics.classification import MultilabelF1Score, MultilabelAccuracy, MultilabelStatScores\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "608458f4411e37bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_path = 'dataset/04_comments_annotated-values.csv'\n",
    "data = pd.read_csv(file_path, delimiter=';')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:31.569166200Z",
     "start_time": "2024-04-19T14:24:31.439077600Z"
    }
   },
   "id": "dcbfdf82a33b855d",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                  c_id                                             c_text  \\\n0  1391717608802631681  Wer so ein Profilbild wie sie hochl√§dt kann nu...   \n1  1389188826799673345  Willst du jetzt etwa behaupten das Querdenker ...   \n2  1385241285645291521  Aber Bild hat doch gerade deswegen und diesbez...   \n3  1385240437988986887  Das sehe ich auch genau so. Dieser Brinkhaus i...   \n4  1389640445790199809  Mit den Milliarden Unterst√ºtzungsgeldern die s...   \n\n               date  conv_id reaction1 reaction2  Ambiguous  Objective  \\\n0  10.05.2021 11:31      NaN       NaN       NaN        0.0        0.0   \n1  03.05.2021 12:03      NaN       NaN       NaN        1.0        0.0   \n2  22.04.2021 14:37      NaN       NaN       NaN        0.0        1.0   \n3  22.04.2021 14:33      NaN       NaN       NaN        1.0        0.0   \n4  04.05.2021 17:57      NaN       NaN       NaN        0.0        0.0   \n\n   Subjective  Disputed  Generalisation0  Generalisation1  Generalisation2  \\\n0         1.0       0.0                0                0                0   \n1         1.0       0.0                0                0                0   \n2         1.0       0.0                0                1                0   \n3         1.0       0.0                1                0                0   \n4         1.0       0.0                0                0                1   \n\n   Generalisation3  \n0                1  \n1                1  \n2                0  \n3                0  \n4                0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_id</th>\n      <th>c_text</th>\n      <th>date</th>\n      <th>conv_id</th>\n      <th>reaction1</th>\n      <th>reaction2</th>\n      <th>Ambiguous</th>\n      <th>Objective</th>\n      <th>Subjective</th>\n      <th>Disputed</th>\n      <th>Generalisation0</th>\n      <th>Generalisation1</th>\n      <th>Generalisation2</th>\n      <th>Generalisation3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1391717608802631681</td>\n      <td>Wer so ein Profilbild wie sie hochl√§dt kann nu...</td>\n      <td>10.05.2021 11:31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1389188826799673345</td>\n      <td>Willst du jetzt etwa behaupten das Querdenker ...</td>\n      <td>03.05.2021 12:03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1385241285645291521</td>\n      <td>Aber Bild hat doch gerade deswegen und diesbez...</td>\n      <td>22.04.2021 14:37</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1385240437988986887</td>\n      <td>Das sehe ich auch genau so. Dieser Brinkhaus i...</td>\n      <td>22.04.2021 14:33</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1389640445790199809</td>\n      <td>Mit den Milliarden Unterst√ºtzungsgeldern die s...</td>\n      <td>04.05.2021 17:57</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:31.596219100Z",
     "start_time": "2024-04-19T14:24:31.516532500Z"
    }
   },
   "id": "d4ead10737c28116",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove test-data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22cedf9382f9c921"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_data_ids = [\n",
    "    1405047474310553601,\n",
    "    1388783647403220994,\n",
    "    1387373196916281344,\n",
    "    1405544796559601673,\n",
    "    1401594561835773957,\n",
    "    1405219910960156675,\n",
    "    1394285068944818176,\n",
    "    1405106839642062848,\n",
    "    1403073727332560902,\n",
    "    1406556368241369090,\n",
    "    1384598185356767235,\n",
    "    1398590532167864320,\n",
    "    1393517517927223301,\n",
    "    1404378018928267264,\n",
    "    1387505263159218179\n",
    "]\n",
    "\n",
    "sample_data = data[data['c_id'].isin(sample_data_ids)]\n",
    "data = data[~data['c_id'].isin(sample_data_ids)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:31.651217Z",
     "start_time": "2024-04-19T14:24:31.579163700Z"
    }
   },
   "id": "a2cf97529c466ffd",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                     c_id                                             c_text  \\\n1485  1405047474310553601  Nein, nicht in einen Tiopf. Die Mitesser-NGO G...   \n1487  1393517517927223301  √Ñ√§√§hm... da m√ºsste man halt jetzt wissen, dass...   \n1492  1388783647403220994  Wer liest das? Mal ehrlich jetzt, wenn dieses ...   \n1493  1387373196916281344  Im Gegensatz etwa zum \"Fl√ºgel\" der AfD damals....   \n1505  1404378018928267264  Biergarten ist gesellschaftlich notwendiger, g...   \n1526  1405544796559601673  ich sage nicht dass wissenschaft gekauft ist. ...   \n1529  1387505263159218179  Corona gibt es sehr wohl, aber wo stecken sich...   \n1545  1401594561835773957  Die brauen Rattenf√§nger bleiben au√üen vor und ...   \n1556  1405219910960156675           Dann waren es wohl die falschen Medien..   \n1561  1394285068944818176  Aber das macht doch die Situation f√ºr Juden HI...   \n1577  1405106839642062848  Wir √ºbernehmen volle Verantwortung f√ºr diesen ...   \n1624  1403073727332560902  Im gegensatz zu dir tue ich das. und f√ºr die c...   \n1689  1406556368241369090  Was hat dann Bandenwerbung im Sport verloren? ...   \n1722  1384598185356767235  Wer die Gr√ºnen w√§hlt, hat die Kontrolle √ºber s...   \n1733  1398590532167864320  So ein Bl√∂dsinn. F√ºhlt ihr euch frei? Frei von...   \n\n                  date       conv_id  \\\n1485  16.06.2021 06:19  1.404880e+18   \n1487  15.05.2021 10:44  1.393101e+18   \n1492  02.05.2021 09:13  1.388210e+18   \n1493  28.04.2021 11:48  1.387325e+18   \n1505  14.06.2021 09:59  1.403864e+18   \n1526  17.06.2021 15:16  1.404880e+18   \n1529  28.04.2021 20:33  1.387325e+18   \n1545  06.06.2021 17:39  1.401583e+18   \n1556  16.06.2021 17:45  1.405213e+18   \n1561  17.05.2021 13:33  1.393929e+18   \n1577  16.06.2021 10:15  1.404880e+18   \n1624  10.06.2021 19:36  1.401583e+18   \n1689  20.06.2021 10:15  1.406508e+18   \n1722  20.04.2021 20:01  1.384598e+18   \n1733  29.05.2021 10:42  1.398384e+18   \n\n                                              reaction1  \\\n1485  Ich werte das als impulsgetiebene Antwort. Bit...   \n1487  100%. Ich hoffe er schreibt es sich hinter sei...   \n1492  Sie fragen, weshalb er ein Faschist sei. Ich b...   \n1493  Jetzt wird's aber sehr beliebig. Sind denn der...   \n1505  Du scheinst dich sehr auf Herrn Reitschuster e...   \n1526  das problem ist dass die industrielle landwirt...   \n1529  Ja, aber genau das ist doch das Problem. Die L...   \n1545  Jo, das stimmt. Aber dass die Bearbock Crew im...   \n1556  Meinen Sie verantwortungslose Eltern, die den ...   \n1561                       Ja, aber nur auf dem Papier!   \n1577  Die haben Tatsache beim Spiel nicht versucht u...   \n1624  ... wieder Quatsch ... aber Querdenker leben j...   \n1689  Ihre Drogen w√ºrde ich auch gerne nehmenüòÇüòÇ Also...   \n1722  Und wer die AfD w√§hlt hat die Kontrolle √ºber s...   \n1733  Freizeit ist vor allem Selbstbestimmung und di...   \n\n                                              reaction2  Ambiguous  Objective  \\\n1485  Jeder Mensch mit klarem Verstand erkennt bei d...        1.0        0.0   \n1487  Es ist immer wieder sch√∂n zu sehen und zu h√∂re...        0.0        1.0   \n1492                             Dann sagen Sie es mir?        1.0        0.0   \n1493  Das negieren des staatlichen Gewaltmonopols is...        0.0        1.0   \n1505               Daf√ºr hattet ihr ne Ausgangssperre üòâ        0.0        1.0   \n1526  Warum ist es \"das √úbel\"? Mit vorindustriellen ...        0.0        1.0   \n1529  Ja aber warum m√ºssen denn alle seit einem Jahr...        0.0        1.0   \n1545                 Btw..wieviel hat die Afd verloren?        1.0        0.0   \n1556             Welche sind denn die richtigen Medien?        0.0        0.0   \n1561                     Ja, Deutsche auf dem \"Papier\"!        0.0        0.0   \n1577  Fakt ist aber dass die aktion: - illegal ist -...        0.0        1.0   \n1624  wer zu solchen worten greift, kehrt besser vor...        1.0        0.0   \n1689               Wie dumm ist Ihre Aussage bitte!? ü§¶ü§¶        1.0        0.0   \n1722  Es gibt nichts besseres als die AfD. Alles Men...        0.0        0.0   \n1733  Erkl√§re mir mal, weshalb ich nicht frei bin. W...        1.0        0.0   \n\n      Subjective  Disputed  Generalisation0  Generalisation1  Generalisation2  \\\n1485         1.0       1.0                1                0                0   \n1487         1.0       0.0                0                1                0   \n1492         1.0       1.0                0                1                0   \n1493         1.0       1.0                1                0                0   \n1505         1.0       1.0                0                0                1   \n1526         1.0       1.0                0                1                0   \n1529         1.0       1.0                0                0                1   \n1545         1.0       1.0                1                0                0   \n1556         1.0       1.0                0                1                0   \n1561         1.0       1.0                0                0                1   \n1577         1.0       1.0                1                0                0   \n1624         1.0       1.0                0                1                0   \n1689         1.0       0.0                0                1                0   \n1722         1.0       1.0                0                1                0   \n1733         1.0       1.0                0                1                0   \n\n      Generalisation3  \n1485                0  \n1487                0  \n1492                0  \n1493                0  \n1505                0  \n1526                0  \n1529                0  \n1545                0  \n1556                0  \n1561                0  \n1577                0  \n1624                0  \n1689                0  \n1722                0  \n1733                0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_id</th>\n      <th>c_text</th>\n      <th>date</th>\n      <th>conv_id</th>\n      <th>reaction1</th>\n      <th>reaction2</th>\n      <th>Ambiguous</th>\n      <th>Objective</th>\n      <th>Subjective</th>\n      <th>Disputed</th>\n      <th>Generalisation0</th>\n      <th>Generalisation1</th>\n      <th>Generalisation2</th>\n      <th>Generalisation3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1485</th>\n      <td>1405047474310553601</td>\n      <td>Nein, nicht in einen Tiopf. Die Mitesser-NGO G...</td>\n      <td>16.06.2021 06:19</td>\n      <td>1.404880e+18</td>\n      <td>Ich werte das als impulsgetiebene Antwort. Bit...</td>\n      <td>Jeder Mensch mit klarem Verstand erkennt bei d...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1487</th>\n      <td>1393517517927223301</td>\n      <td>√Ñ√§√§hm... da m√ºsste man halt jetzt wissen, dass...</td>\n      <td>15.05.2021 10:44</td>\n      <td>1.393101e+18</td>\n      <td>100%. Ich hoffe er schreibt es sich hinter sei...</td>\n      <td>Es ist immer wieder sch√∂n zu sehen und zu h√∂re...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1492</th>\n      <td>1388783647403220994</td>\n      <td>Wer liest das? Mal ehrlich jetzt, wenn dieses ...</td>\n      <td>02.05.2021 09:13</td>\n      <td>1.388210e+18</td>\n      <td>Sie fragen, weshalb er ein Faschist sei. Ich b...</td>\n      <td>Dann sagen Sie es mir?</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1493</th>\n      <td>1387373196916281344</td>\n      <td>Im Gegensatz etwa zum \"Fl√ºgel\" der AfD damals....</td>\n      <td>28.04.2021 11:48</td>\n      <td>1.387325e+18</td>\n      <td>Jetzt wird's aber sehr beliebig. Sind denn der...</td>\n      <td>Das negieren des staatlichen Gewaltmonopols is...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1505</th>\n      <td>1404378018928267264</td>\n      <td>Biergarten ist gesellschaftlich notwendiger, g...</td>\n      <td>14.06.2021 09:59</td>\n      <td>1.403864e+18</td>\n      <td>Du scheinst dich sehr auf Herrn Reitschuster e...</td>\n      <td>Daf√ºr hattet ihr ne Ausgangssperre üòâ</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1526</th>\n      <td>1405544796559601673</td>\n      <td>ich sage nicht dass wissenschaft gekauft ist. ...</td>\n      <td>17.06.2021 15:16</td>\n      <td>1.404880e+18</td>\n      <td>das problem ist dass die industrielle landwirt...</td>\n      <td>Warum ist es \"das √úbel\"? Mit vorindustriellen ...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1529</th>\n      <td>1387505263159218179</td>\n      <td>Corona gibt es sehr wohl, aber wo stecken sich...</td>\n      <td>28.04.2021 20:33</td>\n      <td>1.387325e+18</td>\n      <td>Ja, aber genau das ist doch das Problem. Die L...</td>\n      <td>Ja aber warum m√ºssen denn alle seit einem Jahr...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1545</th>\n      <td>1401594561835773957</td>\n      <td>Die brauen Rattenf√§nger bleiben au√üen vor und ...</td>\n      <td>06.06.2021 17:39</td>\n      <td>1.401583e+18</td>\n      <td>Jo, das stimmt. Aber dass die Bearbock Crew im...</td>\n      <td>Btw..wieviel hat die Afd verloren?</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1556</th>\n      <td>1405219910960156675</td>\n      <td>Dann waren es wohl die falschen Medien..</td>\n      <td>16.06.2021 17:45</td>\n      <td>1.405213e+18</td>\n      <td>Meinen Sie verantwortungslose Eltern, die den ...</td>\n      <td>Welche sind denn die richtigen Medien?</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1561</th>\n      <td>1394285068944818176</td>\n      <td>Aber das macht doch die Situation f√ºr Juden HI...</td>\n      <td>17.05.2021 13:33</td>\n      <td>1.393929e+18</td>\n      <td>Ja, aber nur auf dem Papier!</td>\n      <td>Ja, Deutsche auf dem \"Papier\"!</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1577</th>\n      <td>1405106839642062848</td>\n      <td>Wir √ºbernehmen volle Verantwortung f√ºr diesen ...</td>\n      <td>16.06.2021 10:15</td>\n      <td>1.404880e+18</td>\n      <td>Die haben Tatsache beim Spiel nicht versucht u...</td>\n      <td>Fakt ist aber dass die aktion: - illegal ist -...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1624</th>\n      <td>1403073727332560902</td>\n      <td>Im gegensatz zu dir tue ich das. und f√ºr die c...</td>\n      <td>10.06.2021 19:36</td>\n      <td>1.401583e+18</td>\n      <td>... wieder Quatsch ... aber Querdenker leben j...</td>\n      <td>wer zu solchen worten greift, kehrt besser vor...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1689</th>\n      <td>1406556368241369090</td>\n      <td>Was hat dann Bandenwerbung im Sport verloren? ...</td>\n      <td>20.06.2021 10:15</td>\n      <td>1.406508e+18</td>\n      <td>Ihre Drogen w√ºrde ich auch gerne nehmenüòÇüòÇ Also...</td>\n      <td>Wie dumm ist Ihre Aussage bitte!? ü§¶ü§¶</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1722</th>\n      <td>1384598185356767235</td>\n      <td>Wer die Gr√ºnen w√§hlt, hat die Kontrolle √ºber s...</td>\n      <td>20.04.2021 20:01</td>\n      <td>1.384598e+18</td>\n      <td>Und wer die AfD w√§hlt hat die Kontrolle √ºber s...</td>\n      <td>Es gibt nichts besseres als die AfD. Alles Men...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1733</th>\n      <td>1398590532167864320</td>\n      <td>So ein Bl√∂dsinn. F√ºhlt ihr euch frei? Frei von...</td>\n      <td>29.05.2021 10:42</td>\n      <td>1.398384e+18</td>\n      <td>Freizeit ist vor allem Selbstbestimmung und di...</td>\n      <td>Erkl√§re mir mal, weshalb ich nicht frei bin. W...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.head(15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:31.750364100Z",
     "start_time": "2024-04-19T14:24:31.655210500Z"
    }
   },
   "id": "de7cb29d3e6249d9",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data structure"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7210ac371a7d7f9d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data.drop(labels=['c_id', 'date', 'conv_id'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:31.898715Z",
     "start_time": "2024-04-19T14:24:31.727288300Z"
    }
   },
   "id": "64a2e61fbac700ff",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              c_text reaction1 reaction2  \\\n0  Wer so ein Profilbild wie sie hochl√§dt kann nu...       NaN       NaN   \n1  Willst du jetzt etwa behaupten das Querdenker ...       NaN       NaN   \n2  Aber Bild hat doch gerade deswegen und diesbez...       NaN       NaN   \n3  Das sehe ich auch genau so. Dieser Brinkhaus i...       NaN       NaN   \n4  Mit den Milliarden Unterst√ºtzungsgeldern die s...       NaN       NaN   \n\n   Ambiguous  Objective  Subjective  Disputed  Generalisation0  \\\n0        0.0        0.0         1.0       0.0                0   \n1        1.0        0.0         1.0       0.0                0   \n2        0.0        1.0         1.0       0.0                0   \n3        1.0        0.0         1.0       0.0                1   \n4        0.0        0.0         1.0       0.0                0   \n\n   Generalisation1  Generalisation2  Generalisation3  \n0                0                0                1  \n1                0                0                1  \n2                1                0                0  \n3                0                0                0  \n4                0                1                0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_text</th>\n      <th>reaction1</th>\n      <th>reaction2</th>\n      <th>Ambiguous</th>\n      <th>Objective</th>\n      <th>Subjective</th>\n      <th>Disputed</th>\n      <th>Generalisation0</th>\n      <th>Generalisation1</th>\n      <th>Generalisation2</th>\n      <th>Generalisation3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wer so ein Profilbild wie sie hochl√§dt kann nu...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Willst du jetzt etwa behaupten das Querdenker ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aber Bild hat doch gerade deswegen und diesbez...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Das sehe ich auch genau so. Dieser Brinkhaus i...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mit den Milliarden Unterst√ºtzungsgeldern die s...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:32.053495800Z",
     "start_time": "2024-04-19T14:24:31.878925300Z"
    }
   },
   "id": "521a979d09eab60f",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ba42cb29e4cdfbe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target_list = ['Generalisation0', 'Generalisation1', 'Generalisation2', 'Generalisation3', 'Ambiguous', 'Objective', 'Subjective', 'Disputed']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:32.214521500Z",
     "start_time": "2024-04-19T14:24:32.016509100Z"
    }
   },
   "id": "1422dbc9d69f6b84",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "VALID_BATCH_SIZE = 64\n",
    "EPOCHS = 6\n",
    "LEARNING_RATE = 1e-5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:32.345052100Z",
     "start_time": "2024-04-19T14:24:32.197583800Z"
    }
   },
   "id": "387a20c9131d19a6",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "def get_encodings(text, reaction1, reaction2):\n",
    "    text = str(text)\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    reaction1 = str(reaction1)\n",
    "    reaction1 = \" \".join(reaction1.split())\n",
    "    \n",
    "    reaction2 = str(reaction2)\n",
    "    reaction2 = \" \".join(reaction2.split())\n",
    "    \n",
    "    encodings = tokenizer.__call__(\n",
    "            text + ' [SEP] ' + reaction1 + ' ' + reaction2, \n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    \n",
    "    return encodings['input_ids'], encodings['attention_mask'], encodings['token_type_ids']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:35.322412800Z",
     "start_time": "2024-04-19T14:24:32.352055200Z"
    }
   },
   "id": "c75a413702e0692a",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset (torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.title = self.df['c_text']\n",
    "        self.reaction1 = self.df['reaction1']\n",
    "        self.reaction2 = self.df['reaction2']\n",
    "        self.targets = self.df[target_list].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids, attention_mask, token_type_ids = get_encodings(self.title[index], self.reaction1[index], self.reaction2[index])\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids.flatten(),\n",
    "            'attention_mask': attention_mask.flatten(),\n",
    "            'token_type_ids': token_type_ids.flatten(),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:35.350258800Z",
     "start_time": "2024-04-19T14:24:35.325409400Z"
    }
   },
   "id": "19838c24cd78475a",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0cce338ae2f8979"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2373, 11)\n",
      "train_data (1661, 11)\n",
      "validation_data (470, 11)\n",
      "test_data (242, 11)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.7\n",
    "val_size = 0.66 # (Two thirds of the remaining 30%)\n",
    "\n",
    "print(data.shape)\n",
    "train_data = data.sample(frac=train_size, random_state=200)\n",
    "non_training_data = data.drop(train_data.index)\n",
    "validation_data = non_training_data.sample(frac=val_size, random_state=200)\n",
    "test_data = non_training_data.drop(validation_data.index)\n",
    "\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "validation_data = validation_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "print('train_data', train_data.shape)\n",
    "print('validation_data', validation_data.shape)\n",
    "print('test_data', test_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:35.421584700Z",
     "start_time": "2024-04-19T14:24:35.342255Z"
    }
   },
   "id": "f6dc9c521b03eb81",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = CustomDataset(train_data, tokenizer, MAX_LEN)\n",
    "validation_data = CustomDataset(validation_data, tokenizer, MAX_LEN)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:35.455227100Z",
     "start_time": "2024-04-19T14:24:35.369227900Z"
    }
   },
   "id": "c98ceceb0f1dec9c",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "validation_data_loader = torch.utils.data.DataLoader(validation_data, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:35.538114600Z",
     "start_time": "2024-04-19T14:24:35.382840900Z"
    }
   },
   "id": "47978d8dfe1ea61e",
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d13e73dda01415c4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:35.568111300Z",
     "start_time": "2024-04-19T14:24:35.416934200Z"
    }
   },
   "id": "ef570748a9fcbd15",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath, model, optimizer):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    valid_f1_score_weight = checkpoint['valid_f1_score_weight']\n",
    "    \n",
    "    print(f'Loaded model with the weighted F1-Score of: {valid_f1_score_weight} and epoch: {checkpoint[\"epoch\"]}')\n",
    "    \n",
    "    return model, optimizer, checkpoint['epoch'], valid_f1_score_weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:35.571111300Z",
     "start_time": "2024-04-19T14:24:35.427581100Z"
    }
   },
   "id": "baf1ebf16817107c",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, file_path, best_model_path):\n",
    "    torch.save(state, file_path)\n",
    "    if is_best:\n",
    "        shutil.copy(file_path, best_model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:35.597643Z",
     "start_time": "2024-04-19T14:24:35.441058900Z"
    }
   },
   "id": "cbf72a1ad72fb292",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 8)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        pooler = self.classifier(pooler)\n",
    "        output = self.sigmoid(pooler)\n",
    "        \n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:35.623644100Z",
     "start_time": "2024-04-19T14:24:35.454230800Z"
    }
   },
   "id": "7fccbde71b8662c5",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "BERTClass(\n  (l1): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=768, out_features=8, bias=True)\n  (sigmoid): Sigmoid()\n)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClass()\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:36.541735800Z",
     "start_time": "2024-04-19T14:24:35.474429800Z"
    }
   },
   "id": "ee90deb2bcb98ceb",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5086,  3.8727,  8.7254, 34.4179,  3.8627,  3.9232,  0.1824,  2.4642],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "pos_weights = []\n",
    "for target in target_list:\n",
    "    num_positive = (data[target] == 1).sum()\n",
    "    num_negative = len(data[target]) - num_positive\n",
    "    pos_weights.append(num_negative/num_positive)\n",
    "\n",
    "pos_weights = torch.Tensor(pos_weights).to(device)\n",
    "print(pos_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:36.570908600Z",
     "start_time": "2024-04-19T14:24:36.551591Z"
    }
   },
   "id": "ce93bba7310ff78e",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_function(output, target):\n",
    "    return torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights)(output, target)\n",
    "\n",
    "def metrics_function(output, target):\n",
    "    metNone = MultilabelStatScores(num_labels=8, average='none', threshold=0.5).to(device)\n",
    "    metMicro = MultilabelStatScores(num_labels=8, average='micro', threshold=0.5).to(device)\n",
    "    metMacro = MultilabelStatScores(num_labels=8, average='macro', threshold=0.5).to(device)\n",
    "    metWeighted = MultilabelStatScores(num_labels=8, average='weighted', threshold=0.5).to(device)\n",
    "    output_text = f'Metrics [TP, FP, TN, FN, SUP]: \\tNone: {metNone(output, target)} \\tMicro: {metMicro(output, target)} \\tMacro: {metMacro(output, target)} \\tWeighted: {metWeighted(output, target)}'\n",
    "    \n",
    "    del metNone, metMicro, metMacro, metWeighted\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "def accuracy_function(output, target):\n",
    "    mlaNone = MultilabelAccuracy(num_labels=8, average='none', threshold=0.5).to(device)\n",
    "    mlaMicro = MultilabelAccuracy(num_labels=8, average='micro', threshold=0.5).to(device)\n",
    "    mlaMacro = MultilabelAccuracy(num_labels=8, average='macro', threshold=0.5).to(device)\n",
    "    mlaWeighted = MultilabelAccuracy(num_labels=8, average='weighted', threshold=0.5).to(device)\n",
    "    output_text = f'Accuracy: \\tNone: {mlaNone(output, target)} \\tMicro: {mlaMicro(output, target)} \\tMacro: {mlaMacro(output, target)} \\tWeighted: {mlaWeighted(output, target)}'\n",
    "    \n",
    "    del mlaNone, mlaMicro, mlaMacro, mlaWeighted\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "def f1_score_function(output, target):    \n",
    "    mlf1None = MultilabelF1Score(num_labels=8, average='none', threshold=0.5).to(device)\n",
    "    mlf1Micro = MultilabelF1Score(num_labels=8, average='micro', threshold=0.5).to(device)\n",
    "    mlf1Macro = MultilabelF1Score(num_labels=8, average='macro', threshold=0.5).to(device)\n",
    "    mlf1Weighted = MultilabelF1Score(num_labels=8, average='weighted', threshold=0.5).to(device)\n",
    "    \n",
    "    mlf1WeightedValue = mlf1Weighted(output, target)\n",
    "    mlf1WeightedValue = mlf1WeightedValue.item()\n",
    "    \n",
    "    output_text = f'F1 Score: \\tNone: {mlf1None(output, target)} \\tMicro: {mlf1Micro(output, target)} \\tMacro: {mlf1Macro(output, target)} \\tWeighted: {mlf1WeightedValue}'\n",
    "    \n",
    "    del mlf1None, mlf1Micro, mlf1Macro\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return output_text, mlf1WeightedValue\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:36.697757800Z",
     "start_time": "2024-04-19T14:24:36.565464800Z"
    }
   },
   "id": "5c65abe9e8d153af",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "valid_loss = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:36.699758800Z",
     "start_time": "2024-04-19T14:24:36.574916600Z"
    }
   },
   "id": "3a800df2570f167c",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(n_epochs, training_loader, validation_loader, model, optimizer, checkpoint_path, best_model_path):\n",
    "    valid_f1_score_best = 0.0\n",
    "    model_start_time = timer()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        epoch_start_time = timer()\n",
    "        \n",
    "        # Training Loop\n",
    "        model.train()\n",
    "        \n",
    "        train_output = torch.Tensor().to(device)\n",
    "        train_target = torch.Tensor().to(device)\n",
    "        \n",
    "        for index, batch in enumerate(training_loader, 0):\n",
    "            input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "            attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = batch['targets'].to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            \n",
    "            del input_ids, attention_mask, token_type_ids\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            loss = loss_function(outputs, targets)\n",
    "            train_loss.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_output = torch.cat((train_output, outputs), dim=0)\n",
    "            train_target = torch.cat((train_target, targets), dim=0)\n",
    "        \n",
    "        train_metrics = metrics_function(train_output, train_target)\n",
    "        train_accuracy = accuracy_function(train_output, train_target)\n",
    "        train_f1_score, train_f1_score_weight = f1_score_function(train_output, train_target)\n",
    "            \n",
    "        del train_output, train_target\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Validation Loop\n",
    "        model.eval()\n",
    "        \n",
    "        validation_output = torch.Tensor().to(device)\n",
    "        validation_target = torch.Tensor().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for index, batch in enumerate(validation_loader, 0):\n",
    "                input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "                attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "                token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "                targets = batch['targets'].to(device, dtype=torch.float)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "                \n",
    "                valid_loss.append(loss_function(outputs, targets).item())\n",
    "                \n",
    "                del input_ids, attention_mask, token_type_ids\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                validation_output = torch.cat((validation_output, outputs), dim=0)\n",
    "                validation_target = torch.cat((validation_target, targets), dim=0)\n",
    "        \n",
    "        valid_metrics = metrics_function(validation_output, validation_target)\n",
    "        valid_accuracy = accuracy_function(validation_output, validation_target)\n",
    "        valid_f1_score, valid_f1_score_weight = f1_score_function(validation_output, validation_target)\n",
    "\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'valid_f1_score_weight': valid_f1_score_weight,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        \n",
    "        if valid_f1_score_weight > valid_f1_score_best:\n",
    "            valid_f1_score_best = valid_f1_score_weight\n",
    "            save_checkpoint(checkpoint, True, checkpoint_path, best_model_path)\n",
    "        else:\n",
    "            save_checkpoint(checkpoint, False, checkpoint_path, best_model_path)\n",
    "        \n",
    "        print(f'\\n\\nEpoch: {epoch} \\tTime: {int(timer()-epoch_start_time)}s')\n",
    "        print(f'\\tTraining: \\n\\t\\t{train_metrics} \\n\\t\\t{train_accuracy} \\n\\t\\t{train_f1_score}')\n",
    "        print(f'\\tValidation: \\n\\t\\t{valid_metrics} \\n\\t\\t{valid_accuracy} \\n\\t\\t{valid_f1_score}')\n",
    "        del valid_metrics, valid_accuracy, valid_f1_score, train_metrics, train_accuracy, train_f1_score\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    print(f'\\n\\nTraining time: {int(timer()-model_start_time)}s')\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:36.735759200Z",
     "start_time": "2024-04-19T14:24:36.594946200Z"
    }
   },
   "id": "40390e5e2ca36958",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and evaluate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6661621cfb8ea3f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = './model/checkpoint.pth'\n",
    "BEST_MODEL_PATH = './model/best_model.pth'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:24:36.738759200Z",
     "start_time": "2024-04-19T14:24:36.603237900Z"
    }
   },
   "id": "ef67bbd5acbea362",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 1 \tTime: 581s\n",
      "\tTraining: \n",
      "\t\tMetrics [TP, FP, TN, FN, SUP]: \tNone: tensor([[  86,   49,  515, 1011, 1097],\n",
      "        [   7,   20, 1300,  334,  341],\n",
      "        [  18,  155, 1334,  154,  172],\n",
      "        [   4,  190, 1421,   46,   50],\n",
      "        [  43,  181, 1131,  306,  349],\n",
      "        [   1,    4, 1321,  335,  336],\n",
      "        [1291,  244,   19,  107, 1398],\n",
      "        [ 117,  248,  923,  373,  490]], device='cuda:0') \tMicro: tensor([1567, 1091, 7964, 2666, 4233], device='cuda:0') \tMacro: tensor([195.8750, 136.3750, 995.5000, 333.2500, 529.1250], device='cuda:0') \tWeighted: tensor([467.1665, 147.3844, 620.4016, 426.0475, 893.2141], device='cuda:0') \n",
      "\t\tAccuracy: \tNone: tensor([0.3618, 0.7869, 0.8140, 0.8579, 0.7068, 0.7959, 0.7887, 0.6261],\n",
      "       device='cuda:0') \tMicro: 0.7172636985778809 \tMacro: 0.7172636985778809 \tWeighted: 0.6547671556472778 \n",
      "\t\tF1 Score: \tNone: tensor([0.1396, 0.0380, 0.1043, 0.0328, 0.1501, 0.0059, 0.8803, 0.2737],\n",
      "       device='cuda:0') \tMicro: 0.45479610562324524 \tMacro: 0.20309405028820038 \tWeighted: 0.3791321814060211\n",
      "\tValidation: \n",
      "\t\tMetrics [TP, FP, TN, FN, SUP]: \tNone: tensor([[  0,   0, 159, 311, 311],\n",
      "        [  0,   0, 370, 100, 100],\n",
      "        [  0,   0, 422,  48,  48],\n",
      "        [  0,   0, 459,  11,  11],\n",
      "        [  0,   0, 377,  93,  93],\n",
      "        [  0,   0, 372,  98,  98],\n",
      "        [232,  36,  35, 167, 399],\n",
      "        [  0,   0, 332, 138, 138]], device='cuda:0') \tMicro: tensor([ 232,   36, 2526,  966, 1198], device='cuda:0') \tMacro: tensor([ 29.0000,   4.5000, 315.7500, 120.7500, 149.7500], device='cuda:0') \tWeighted: tensor([ 77.2688,  11.9900, 202.8815, 177.8598, 255.1285], device='cuda:0') \n",
      "\t\tAccuracy: \tNone: tensor([0.3383, 0.7872, 0.8979, 0.9766, 0.8021, 0.7915, 0.5681, 0.7064],\n",
      "       device='cuda:0') \tMicro: 0.7335106134414673 \tMacro: 0.7335106134414673 \tWeighted: 0.5960643887519836 \n",
      "\t\tF1 Score: \tNone: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6957, 0.0000],\n",
      "       device='cuda:0') \tMicro: 0.3165075182914734 \tMacro: 0.08695652335882187 \tWeighted: 0.23169049620628357\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m trained_model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_data_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCHECKPOINT_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mBEST_MODEL_PATH\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[47], line 14\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(n_epochs, training_loader, validation_loader, model, optimizer, checkpoint_path, best_model_path)\u001B[0m\n\u001B[0;32m     11\u001B[0m train_target \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(training_loader, \u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m---> 14\u001B[0m     input_ids \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput_ids\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlong\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m     16\u001B[0m     token_type_ids \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trained_model = train_model(EPOCHS, train_data_loader, validation_data_loader, model, optimizer, CHECKPOINT_PATH, BEST_MODEL_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:42:18.706535700Z",
     "start_time": "2024-04-19T14:24:36.610237700Z"
    }
   },
   "id": "da94e78a115d5864",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.plot(list(range(1, EPOCHS+1)), train_loss)\n",
    "plt.ylabel('train loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('Train loss; Learning rate: ' + LEARNING_RATE + '; Batch size: ' + TRAIN_BATCH_SIZE + '; Epochs: ' + EPOCHS);\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:42:18.717534400Z",
     "start_time": "2024-04-19T14:42:18.716535700Z"
    }
   },
   "id": "60391ec7f3d778a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.plot(list(range(1, EPOCHS+1)), train_loss)\n",
    "plt.ylabel('validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('Validation loss; Learning rate: ' + LEARNING_RATE + '; Batch size: ' + TRAIN_BATCH_SIZE + '; Epochs: ' + EPOCHS);\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:42:18.762539500Z",
     "start_time": "2024-04-19T14:42:18.717534400Z"
    }
   },
   "id": "daccb9b2031e74eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89299a35ae1a6846"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_model = BERTClass()\n",
    "pred_model.to(device)\n",
    "model = load_checkpoint(BEST_MODEL_PATH, pred_model, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-19T14:42:18.720541700Z"
    }
   },
   "id": "f18f8acb1f1606ec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-19T14:42:18.725533700Z"
    }
   },
   "id": "f70a1da4d04203e1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d49abb24b05e2fdb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_output = torch.Tensor().to(device)\n",
    "test_target = torch.Tensor().to(device)\n",
    "\n",
    "for index, row in test_data.iterrows():\n",
    "    input_ids, attention_mask, token_type_ids = get_encodings(row[\"c_text\"], row[\"reaction1\"], row[\"reaction2\"])\n",
    "    pred_model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = input_ids.to(device, dtype=torch.long)\n",
    "        attention_mask = attention_mask.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        \n",
    "        targets = torch.Tensor([[row[\"Generalisation0\"], row[\"Generalisation1\"], row[\"Generalisation2\"], row[\"Generalisation3\"], row[\"Ambiguous\"], row[\"Objective\"], row[\"Subjective\"], row[\"Disputed\"]]])\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "        \n",
    "        outputs = pred_model(input_ids, attention_mask, token_type_ids)\n",
    "        outputs = torch.Tensor(outputs)\n",
    "        outputs = outputs.to(device, dtype=torch.float)\n",
    "        \n",
    "        test_output = torch.cat((test_output, outputs), dim=0)\n",
    "        test_target = torch.cat((test_target, targets), dim=0)\n",
    "\n",
    "test_metrics = metrics_function(test_output, test_target)\n",
    "test_accuracy = accuracy_function(test_output, test_target)\n",
    "test_f1_score, valid_f1_score_weight = f1_score_function(test_output, test_target)\n",
    "\n",
    "print(f'\\tTest: \\n\\t\\t{test_metrics} \\n\\t\\t{test_accuracy} \\n\\t\\t{test_f1_score}')\n",
    "del test_metrics, test_accuracy, test_f1_score\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-19T14:42:18.728535400Z"
    }
   },
   "id": "719fe9031faacd00",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get Predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63794d5155241a97"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_prediction(row): \n",
    "    input_ids, attention_mask, token_type_ids = get_encodings(row[\"c_text\"], row[\"reaction1\"], row[\"reaction2\"])\n",
    "    \n",
    "    pred_model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = input_ids.to(device, dtype=torch.long)\n",
    "        attention_mask = attention_mask.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        \n",
    "        outputs = pred_model(input_ids, attention_mask, token_type_ids)\n",
    "        \n",
    "        generalisation_pred_value = 0\n",
    "        generalisation_pred_prop = 0\n",
    "        if outputs[0][0].item() > generalisation_pred_prop:\n",
    "            generalisation_pred_value = 0\n",
    "            generalisation_pred_prop = outputs[0][0].item()\n",
    "        \n",
    "        if outputs[0][1].item() > generalisation_pred_prop:\n",
    "            generalisation_pred_value = 1\n",
    "            generalisation_pred_prop = outputs[0][1].item()\n",
    "            \n",
    "        if outputs[0][2].item() > generalisation_pred_prop:\n",
    "            generalisation_pred_value = 2\n",
    "            generalisation_pred_prop = outputs[0][2].item()\n",
    "        \n",
    "        if outputs[0][3].item() > generalisation_pred_prop:\n",
    "            generalisation_pred_value = 3\n",
    "        \n",
    "        row['Generalisation_Pred'] = generalisation_pred_value\n",
    "        row['Ambiguous_Pred'] = 1 if outputs[0][4].item() > 0.5 else 0\n",
    "        row['Objective_Pred'] = 1 if outputs[0][5].item() > 0.5 else 0\n",
    "        row['Subjective_Pred'] = 1 if outputs[0][6].item() > 0.5 else 0\n",
    "        row['Disputed_Pred'] = 1 if outputs[0][7].item() > 0.5 else 0\n",
    "        \n",
    "        return row"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-19T14:42:18.732534800Z"
    }
   },
   "id": "d0cfa2385a37cc09",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_pred = []\n",
    "for index, row in sample_data.iterrows():\n",
    "    data_pred.append(get_prediction(row))\n",
    "    \n",
    "data_pred = pd.DataFrame(data_pred)\n",
    "data_pred.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-19T14:42:18.736533300Z"
    }
   },
   "id": "d1540c8f500c02a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_pred.to_csv('dataset/05_predictions-for-test-comments.csv', sep=';', index=False, header=True, encoding='utf-8-sig') "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-19T14:42:18.738535Z"
    }
   },
   "id": "8045b46e5e22c026",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
